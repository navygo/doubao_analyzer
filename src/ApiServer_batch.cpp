
// å¤„ç†æ‰¹é‡åˆ†æè¯·æ±‚
ApiResponse ApiServer::handle_batch_analysis(const std::vector<ApiRequest>& requests)
{
    ApiResponse response;
    nlohmann::json timing_info = nlohmann::json::object();
    double total_start_time = utils::get_current_time();

    std::cout << "ğŸ”„ [æ‰¹é‡åˆ†æ] å¼€å§‹å¤„ç† " << requests.size() << " ä¸ªåª’ä½“æ–‡ä»¶" << std::endl;
    std::cout << "â° [æ—¶é—´æˆ³] è¯·æ±‚æ¥æ”¶æ—¶é—´: " << utils::get_formatted_timestamp() << std::endl;

    try {
        // åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        std::vector<AnalysisTask> tasks;
        tasks.reserve(requests.size());

        for (size_t i = 0; i < requests.size(); ++i) {
            const auto& req = requests[i];

            AnalysisTask task;
            task.id = "batch_" + std::to_string(i) + "_" + utils::get_current_timestamp();
            task.media_url = req.media_url;
            task.media_type = req.media_type;
            task.prompt = req.prompt.empty() ? (req.media_type == "video" ? get_video_prompt() : get_image_prompt()) : req.prompt;
            task.max_tokens = req.max_tokens > 0 ? req.max_tokens : config::DEFAULT_MAX_TOKENS;
            task.video_frames = req.video_frames > 0 ? req.video_frames : config::DEFAULT_VIDEO_FRAMES;
            task.save_to_db = req.save_to_db;

            tasks.push_back(task);
        }

        // æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—å¹¶è·å–futureåˆ—è¡¨
        auto futures = TaskManager::getInstance().addTasks(tasks);

        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        std::vector<TaskResult> results;
        results.reserve(futures.size());

        for (auto& future : futures) {
            results.push_back(future.get());
        }

        // æ„å»ºå“åº”æ•°æ®
        nlohmann::json results_array = nlohmann::json::array();
        int success_count = 0;

        for (const auto& result : results) {
            nlohmann::json result_obj;
            result_obj["task_id"] = result.task_id;
            result_obj["success"] = result.success;

            if (result.success) {
                result_obj["content"] = result.result.content;
                result_obj["tags"] = result.result.tags;
                result_obj["response_time"] = result.result.response_time;
                result_obj["usage"] = result.result.usage;
                success_count++;
            } else {
                result_obj["error"] = result.error;
            }

            results_array.push_back(result_obj);
        }

        // è®¾ç½®å“åº”
        response.success = true;
        response.message = "æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸ: " + std::to_string(success_count) + "/" + std::to_string(requests.size());
        response.data["results"] = results_array;
        response.data["summary"] = {
            {"total", requests.size()},
            {"successful", success_count},
            {"failed", requests.size() - success_count}
        };

        double total_time = utils::get_current_time() - total_start_time;
        timing_info["total_seconds"] = total_time;
        timing_info["pending_tasks"] = TaskManager::getInstance().getPendingTaskCount();
        timing_info["active_threads"] = TaskManager::getInstance().getActiveThreadCount();

        std::cout << "âœ… [æ‰¹é‡åˆ†æ] å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: " << success_count << "/" << requests.size() << std::endl;
        std::cout << "â° [æ—¶é—´æˆ³] è¯·æ±‚å¤„ç†å®Œæˆæ—¶é—´: " << utils::get_formatted_timestamp() << std::endl;
        std::cout << "ğŸ‰ [å®Œæˆ] æ‰¹é‡åˆ†æè¯·æ±‚å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: " << total_time << " ç§’" << std::endl;
    }
    catch (const std::exception& e) {
        response.success = false;
        response.message = "æ‰¹é‡åˆ†æå¤±è´¥: " + std::string(e.what());
        response.error = "Batch analysis error";

        std::cerr << "âŒ [æ‰¹é‡åˆ†æ] å¼‚å¸¸: " << e.what() << std::endl;
    }

    response.data["timing"] = timing_info;
    response.response_time = utils::get_current_time() - total_start_time;

    return response;
}
